---
title: "Data Analysis Skill Test"
author: "Adriano Ribeiro"
date: "7/5/2020"
output:
  html_document: default
  pdf_document: default
---

# Preparations

```{r, message=FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(lubridate)
library(astsa)
library(forecast)
library(xts)
```

# Case1

## Data
```{r}
data <- read.csv("TFP.csv")
str(data)
data$year <- ymd(data$year, truncated = 2)
```

## Analysis

### Exploratory Data Analysis

First, let's check some statistics for each country.
```{r summary}
per_country <- data %>%
  as_tibble() %>%
  pivot_wider(names_from = isocode, values_from =rtfpna)
per_country %>% select(c(USA, MEX, CAN)) %>% summary()
```
Besides that, we could also look at some dispersion measure, such as the standard deviation. They are `r round(sd(per_country$USA),3)`, `r round(sd(per_country$CAN), 3)`, and `r round(sd(per_country$MEX),3)` for the US, Canada and Mexico, respectively.

These statistics show that Mexico had the highest productivity, the biggest difference between maximum and minimum values, and the highest standard deviation. On the other hand, Canada had the smallest max-min difference and standard deviation between these 3 countries. Lastly, the US had the smallest mean throughout this period. To have a better understanding of the path took by the productivity in these three countries, let's take a look at their graph.

```{r plot}
ggplot(data, aes(x=year, y=rtfpna, col=isocode))+
  geom_line(size=1.5)+
  scale_x_date(breaks="5 years", date_labels=(format="%Y"))+
  labs(x="Year", y="TFP", title="TFP (1950-2011)", col="Countries")
```

From the plot, notice first that all three series are converging to the range between .9 and 1. Mexico's TFP increased really fast in the 1950s and in the first half of the 1960s from .8 to 1.3, then it reached a plateau above 1.3 until 1981 to finally slump to the above mentioned range. Also, note that Mexico's TFP had the hugest drop between 2008 and 2009, likely as a result of the Great Depression. Canada's TFP, as the standard deviation showed, did not move much during this period, although it began as the biggest value in 1950, it was just slightly below .9, then it stabilized around 1 between 1965 and 2000 and fell a little afterwards, nevertheless still finishing the period above .9. Finally, the US's TFP that was slightly above .6 in 1950, the minimum point between all these countries, steadily increased throughout the period to reach its maximum in 2011 above 1. 

### Forecast

First of all, let's transform the data in a time series object.

```{r time_series}
data_ts <- ts(per_country[,-1], start=1950, end=2011, frequency=1)
```

The last graph tells us that we should treat each TFP separetely, that is, a model for each country.

**Mexico:**
The serie becomes stationary after differencing twice.

```{r acf_Mex}
acf2(diff(diff(data_ts[,"MEX"])), max.lag = 10)
```

The autocorrelation and partial autocorrelation functions suggest the series could be an ARIMA(0,2,1), ARIMA(2,2,0) or ARIMA(2,2,1). The lowest AIC between these three options is given by the ARIMA(0,2,1) model.

For forecast purpose, we will compare the ARIMA model above against the ETS model in the last 10 years. To do that, let's define a training set, then compare the forecast error of these two models.

```{r fc_test_MEX}
train_MEX <- subset(data_ts[,"MEX"], end=52)
ets_MEX <- ets(train_MEX)
fc_ets_MEX <- forecast(ets_MEX, h=10)
arima_MEX <- arima(train_MEX, order=c(0,2,1))
fc_arima_MEX <- forecast(arima_MEX, h=10)
accuracy(fc_ets_MEX, data_ts[,"MEX"])
accuracy(fc_arima_MEX, data_ts[,"MEX"])
```

Looking at the RMSE, the ARIMA(0,2,1) model performs better than the ETS model on the Test Set. Therefore, here follows a 10 years forecast of the serie.

```{r fc_MEX}
forecast(arima(data_ts[,"MEX"], order=c(0,2,1)), h=10)
autoplot(forecast(arima(data_ts[,"MEX"], order=c(0,2,1)), h=10))
```

**Canada:**
Again, the TFP serie becomes stationary after differencing twice.

```{r acf_CAN}
acf2(diff(diff(data_ts[,"CAN"])))
```
The autocorrelation and partial autocorrelation functions suggest the serie could follow an ARIMA(0,2,3) or ARIMA(2,2,3). The latter generates a smaller AIC than the first.

Let's not proceed comparing the ARIMA(2,2,3) model with the ETS model.

```{r fc_test_CAN}
train_CAN <- subset(data_ts[,"CAN"], end=52)
ets_CAN <- ets(train_CAN)
fc_ets_CAN <- forecast(ets_CAN, h=10)
arima_CAN <- arima(train_CAN, order=c(0,2,3))
fc_arima_CAN <- forecast(arima_CAN, h=10)
accuracy(fc_ets_CAN, data_ts[,"CAN"])
accuracy(fc_arima_CAN, data_ts[,"CAN"])
```

On the training set, the ETS model performs better once it has a smaller RMSE. 

```{r fc_CAN}
forecast(ets(data_ts[,"CAN"]), h=10)
autoplot(forecast(ets(data_ts[,"CAN"]), h=10))
```

Notice that ETS gives a constant as the forecast, this kind of estimate performed better than the ARIMA model (although not showed here, the ARIMA test previewed an upward trend when actual data decreased). There is space for an even improved model as a future work.

**US:**

For the US, the TFP data has an upward trend, thus first differencing was enough to stationarize it.

```{r acf_US}
acf2(diff(data_ts[,"USA"]))
```

The plot does not show any serial correlation after taking the first difference. The suggested model would then be an ARIMA(0,1,0), that is, just a constant with noise.

Next, I'll compare, for the past 10 years of data, this model with two versions of ETS, one with additive trend and another with damped trend. The reason for doing that is to avoid an explosive plath to the TFP as given by the additive trend.

```{r fc_test_US}
train_US <- subset(data_ts[,"USA"], end=52)
ets_US <- ets(train_US)
fc_ets_US <- forecast(ets_US, h=10)
etsD_US <- ets(train_US, damped=TRUE)
fc_etsD_US <- forecast(etsD_US, h=10)
arima_US <- arima(train_US, order=c(0,1,0))
fc_arima_US <- forecast(arima_US, h=10)
accuracy(fc_ets_US, data_ts[,"USA"])
accuracy(fc_etsD_US, data_ts[,"USA"])
accuracy(fc_arima_US, data_ts[,"USA"])
```

The RMSE criterion on the Test Set shows that the ETS model with damped trend performs better than the other two models.

```{r fc_US}
forecast(ets(data_ts[,"USA"], damped=TRUE), h=10)
autoplot(forecast(ets(data_ts[,"USA"], damped=TRUE), h=10))
```

### Other Features

pop Population (in millions).
emp Number of persons engaged (in millions).
avh Average annual hours worked by persons engaged.
hc Index of human capital per person, based on years of schooling (Barro and Lee 2013) and returns
to education (Psacharopoulos 1994).

# Case 2

## Data

```{r}
data2 <- read.csv("data_comexstat.csv")
str(data2)
data2$date <- ymd(data2$date)
```

### Analysis

**Soybeans, Soybean Oil and Soybean Meal Exports:**

The first step to do is to separate the variables we are interested in.

```{r exports}
exports <- data2 %>% as_tibble() %>% filter(type=="Export")
products <- split(x=exports, f=exports$product)
```

To analyze monthly exports of soybeans, soybean oil and soybean meal, we could look at it either in tons or usd.

```{r}
soybeans <- products[["soybeans"]]
soybeans <- aggregate(soybeans[,c("tons","usd")], by=list(soybeans$date), FUN=sum)
soybeans$product <- "soybeans"

soybean_oil <- products[["soybean_oil"]]
soybean_oil <- aggregate(soybean_oil[,c("tons","usd")], by=list(soybean_oil$date), FUN=sum)
soybean_oil$product <- "soybean_oil"

soybean_meal <- products[["soybean_meal"]]
soybean_meal <- aggregate(soybean_meal[,c("tons","usd")], by=list(soybean_meal$date), FUN=sum)
soybean_meal$product <- "soybean_meal"

soy <- rbind(soybeans, soybean_oil, soybean_meal)
colnames(soy)[1] <- "date"

```

The data for tons and usd are, not surprisingly, very similar. Even if the exchange rate floats, the main component of exports trend should be the amount in tons. Below we plot the monthly data (in tons) for each of these products with their trend line. Bear in mind that if usd was used, the pattern would be the same.

```{r plot_tons, message=FALSE}
ggplot(soy, aes(x=date, y=tons, col=product))+
  geom_line()+
  geom_smooth(se=F, method="lm")
```

AJUSTAR GRAFICO, AJUSTAR Y AXIS, COMECAR NO ZERO, COLOCAR MAIS ANOS NO X 

From the plot, we notice that both soybean oil and soybean meal exports did not change much in the past 23 years. On the other hand, soybeans export, that was in a similar level of those two in 1997, increased abruptly. One interpretation is that Brazilian soybeans production grew really fast and was directed to exportation before any transformation. Notice also the similar seasonality of all three products, in which the exports spike in some months of the year, likely during the harvest. For a better understanding of the trend, it is better to look at the annual data.

```{r soy_annual}
soy_tons_ts <- xts(x=cbind(soybeans=soybeans$tons, soybean_oil=soybean_oil$tons, soybean_meal=soybean_meal$tons), order.by=soybeans[,1], frequency=12)

soy_tons_yr <- do.call(rbind, lapply(split(soy_tons_ts, "years"), colSums))

soy_yr_df <- cbind.data.frame(year=seq(ymd("1997", truncated=2), ymd("2019", truncated = 2), by="years"), soy_tons_yr)
soy_yr_df$soybeans_yoy <- 100*(soy_yr_df$soybeans-lag(soy_yr_df$soybeans))/lag(soy_yr_df$soybeans)
soy_yr_df$soybean_oil_yoy <- 100*(soy_yr_df$soybean_oil-lag(soy_yr_df$soybean_oil))/lag(soy_yr_df$soybean_oil)
soy_yr_df$soybean_meal_yoy <- 100*(soy_yr_df$soybean_meal-lag(soy_yr_df$soybean_meal))/lag(soy_yr_df$soybean_meal)

tidy_soy_yr_df <- pivot_longer(data=soy_yr_df, cols=c(soybeans, soybean_oil, soybean_meal), names_to="type")
```

```{r plot_soy_annual}
ggplot(tidy_soy_yr_df, aes(x=year, y=value, col=type))+
  geom_line()
```

COMO SE PODE VER, SOYBEANS DISPARADO, INTERESSANTE O PLOT DO CRESCIMENTO, QUASE SEMPRE MAIOR QUE ZERO
```{r plot_soybeans_growth}
ggplot(data=soy_yr_df, aes(x=year, y=soybeans_yoy))+
  geom_line()+
  geom_hline(yintercept = 0, col="red")
```

**The 3 most important products exported in the last 5 years:**
```{r}
corn <- products[["corn"]]
corn <- aggregate(corn[,c("tons","usd")], by=list(corn$date), FUN=sum)
corn$product <- "corn"

sugar <- products[["sugar"]]
sugar <- aggregate(sugar[,c("tons","usd")], by=list(sugar$date), FUN=sum)
sugar$product <- "sugar"

wheat <- products[["wheat"]]
wheat <- aggregate(wheat[,c("tons","usd")], by=list(wheat$date), FUN=sum)
wheat$product <- "wheat"
```


imports <- data2 %>% filter(type=="Import")





